{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chatbot_response(client,model_name,messages,temperature=0):\n",
    "    input_messages = []\n",
    "    for message in messages:\n",
    "        input_messages.append({'role':message[\"role\"],'content':message[\"content\"]})\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model = model_name,\n",
    "        messages=input_messages,\n",
    "        temperature= temperature, # Index of the response\n",
    "        top_p=0.8, # Probability of the response\n",
    "        max_tokens = 2000 # Maximum number of tokens (words) in the response\n",
    "    ).choices[0].message.content\n",
    "    \n",
    "    return response\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key = os.getenv('RUNPOD_TOKEN'),\n",
    "    base_url= os.getenv('RUNPOD_CHATBOT_URL'),\n",
    "    )\n",
    "model_name = os.getenv(\"MODEL_NAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GET LLM RESPONSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Promt Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structed output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "{\n",
      "    \"country\": \"Germany\",\n",
      "    \"capital\": \"Berlin\"\n",
      "}\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a helpful asisstant that answers questions about capital of countries.\n",
    "Your output should be in a strctured json format exactly like the one bellow. You are not allowed to write anything other than the json object:\n",
    "[\n",
    "{\n",
    "    \"country\": the country that you will get the capital of\n",
    "    \"capital\": the capital of the country stated\n",
    "}\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "messages.append({\"role\": \"user\", \"content\": \"What's the capital of Germany?\"})\n",
    "response = get_chatbot_response(client,model_name,messages)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'country': 'Germany', 'capital': 'Berlin'}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_response = json.loads(response)\n",
    "json_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict, 'Berlin')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(json_response[0]),json_response[0][\"capital\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Structuring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"country\": \"Italy\",\n",
      "        \"capital\": \"Rome\"\n",
      "    },\n",
      "    {\n",
      "        \"country\": \"Germany\",\n",
      "        \"capital\": \"Berlin\"\n",
      "    },\n",
      "    {\n",
      "        \"country\": \"France\",\n",
      "        \"capital\": \"Paris\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "user_input = \"\"\"\n",
    "Get me the capitals of the following countries:\n",
    "```\n",
    "1. Italy\n",
    "2. Germany\n",
    "3. France\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "response = get_chatbot_response(client,model_name,messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_response = json.loads(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Give the model time to think(Chain of thought)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"result\": 4\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"\"\"\n",
    "Calculate the result of this equation: 1+3\n",
    "\n",
    "Your out put should be in a structered json format exactly like the one bellow. You are not allowed to write anything other than the json object:\n",
    "{\n",
    "    result: The final number resulted from the calculating the equation above\n",
    "}\n",
    "\"\"\"\n",
    "messages = [{\"role\": \"system\", \"content\": user_prompt}]\n",
    "response = get_chatbot_response(client,model_name,messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4113098.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "259/2*8654+91072*33-12971"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"result\": 1344449\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"\"\"\n",
    "Calculate the result of this equation: 259/2*8654+91072*33-12971\n",
    "\n",
    "Your out put should be in a structered json format exactly like the one bellow. You are not allowed to write anything other than the json object:\n",
    "{\n",
    "    result: The final number resulted from the calculating the equation above\n",
    "}\n",
    "\"\"\"\n",
    "messages = [{\"role\": \"system\", \"content\": user_prompt}]\n",
    "response = get_chatbot_response(client,model_name,messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"step\": \"First, calculate the division: 259/2 = 129.5. Then, multiply 129.5 by 8654: 129.5 * 8654 = 112,141.5. Next, multiply 91072 by 33: 91072 * 33 = 3,003,336. Now, add 112,141.5 and 3,003,336: 112,141.5 + 3,003,336 = 3,115,477.5. Finally, subtract 12971 from 3,115,477.5: 3,115,477.5 - 12971 = 3,105,706.5.\",\n",
      "    \"result\": 3105706.5\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"\"\"\n",
    "Calculate the result of this equation: 259/2*8654+91072*33-12971\n",
    "\n",
    "Your out put should be in a structered json format exactly like the one bellow. You are not allowed to write anything other than the json object:\n",
    "{\n",
    "    step: This is where you solve the equation bit by bit following the BEDMAS order of operations. You need to show your work and calculate each step leading to the final result. Feel free to write in free text.\n",
    "    result: The final number resulted from the calculating the equation above\n",
    "}\n",
    "\"\"\"\n",
    "messages = [{\"role\": \"system\", \"content\": user_prompt}]\n",
    "response = get_chatbot_response(client,model_name,messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no such thing as an iPhone 16. Apple has not released an iPhone with that model number. The latest iPhone models available in the market are iPhone 13 series, which includes iPhone 13, iPhone 13 Mini, iPhone 13 Pro, and iPhone 13 Pro Max.\n",
      "\n",
      "However, rumors and leaks about the upcoming iPhone 14 series have been circulating online. According to reports, the iPhone 14 series is expected to feature several upgrades and improvements, including:\n",
      "\n",
      "1. New design: The iPhone 14 series is expected to have a new design with a smaller notch, thinner bezels, and a more seamless glass front.\n",
      "2. Improved cameras: The iPhone 14 Pro models are expected to feature a new triple-camera setup with a wider-angle lens, a telephoto lens, and a ultra-wide-angle lens.\n",
      "3. Faster processors: The iPhone 14 series is expected to be powered by Apple's A15 Bionic chip, which will provide faster performance and improved power efficiency.\n",
      "4. Longer battery life: The iPhone 14 series is expected to have longer battery life, with some models offering up to 12 hours of internet use.\n",
      "5. New colors: The iPhone 14 series is expected to be available in new colors, including a new \"Pacific Blue\" color option.\n",
      "6. Improved water resistance: The iPhone 14 series is expected to have improved water resistance, with a rating of IP68, which means it can withstand being submerged in water up to 4 meters for up to 30 minutes.\n",
      "7. New features: The iPhone 14 series is expected to feature new features, such as a new \"Super Retina XDR\" display, improved Face ID, and a new \"MagSafe\" wireless charging system.\n",
      "\n",
      "It's worth noting that these are just rumors and leaks, and Apple has not officially confirmed any of these features. The company typically announces new iPhone models in the fall, so we can expect to see the iPhone 14 series in September or October.\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"\"\"\n",
    "What's new in iphone 16?\n",
    "\"\"\"\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": user_prompt}]\n",
    "response = get_chatbot_response(client,model_name,messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "iphone_16 = \"\"\"\n",
    "The iPhone 16 introduces several exciting updates, making it one of Apple's most advanced smartphones to date. It features a larger 6.1-inch display for the base model and a 6.7-inch screen for the iPhone 16 Plus, with thinner bezels and a more durable Ceramic Shield. The iPhone 16 Pro and Pro Max boast even larger displays, measuring 6.3 and 6.9 inches respectively, offering the thinnest bezels seen on any Apple product so far.\n",
    "\n",
    "Powered by the new A18 chip (A18 Pro for the Pro models), these phones deliver significant performance improvements, with enhanced neural engine capabilities, faster GPU for gaming, and machine learning tasks. The camera systems are also upgraded, with the base iPhone 16 sporting a dual-camera setup with a 48MP main sensor. The Pro models offer a 48MP Ultra Wide and 5x telephoto camera, enhanced by Apple’s \"Camera Control\" button for more flexible photography options.\n",
    "\n",
    "Apple also introduced advanced audio features like \"Audio Mix,\" which uses machine learning to separate background sounds from speech, allowing for more refined audio capture during video recording. Battery life has been extended, especially in the iPhone 16 Pro Max, which is claimed to have the longest-lasting battery of any iPhone \n",
    "9TO5MAC\n",
    "\n",
    "APPLEMAGAZINE\n",
    ".\n",
    "\n",
    "Additionally, Apple has switched to USB-C for faster charging and data transfer, and the Pro models now support up to 2x faster video encoding. The starting prices remain consistent with previous generations, with the iPhone 16 starting at $799, while the Pro models start at $999\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the text, the new features and updates in the iPhone 16 include:\n",
      "\n",
      "1. Larger displays: 6.1-inch for the base model, 6.7-inch for the iPhone 16 Plus, 6.3 inches for the iPhone 16 Pro, and 6.9 inches for the iPhone 16 Pro Max.\n",
      "2. Thinner bezels and a more durable Ceramic Shield.\n",
      "3. New A18 chip (A18 Pro for the Pro models) with improved performance, neural engine capabilities, and faster GPU for gaming and machine learning tasks.\n",
      "4. Upgraded camera systems:\n",
      "\t* Base iPhone 16: dual-camera setup with a 48MP main sensor.\n",
      "\t* Pro models: 48MP Ultra Wide and 5x telephoto camera, with Apple's \"Camera Control\" button for more flexible photography options.\n",
      "5. Advanced audio features, including \"Audio Mix\" for refined audio capture during video recording.\n",
      "6. Extended battery life, especially in the iPhone 16 Pro Max, which has the longest-lasting battery of any iPhone.\n",
      "7. Switch to USB-C for faster charging and data transfer.\n",
      "8. Pro models support up to 2x faster video encoding.\n",
      "9. Starting prices remain consistent with previous generations, with the iPhone 16 starting at $799 and the Pro models starting at $999.\n"
     ]
    }
   ],
   "source": [
    "user_prompt = f\"\"\"\n",
    "{iphone_16}\n",
    "\n",
    "What's new in iphone 16?\n",
    "\"\"\"\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": user_prompt}]\n",
    "response = get_chatbot_response(client,model_name,messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
